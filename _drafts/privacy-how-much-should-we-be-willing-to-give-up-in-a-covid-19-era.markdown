---
title: 'Privacy: how much should we be willing to give up in a COVID-19 era?'
date: 2020-05-05 05:09:00 -04:00
tags:
- COVID-19
- Cybersecurity
Author: Galia Nurko
---

As many countries struggle to manage the COVID-19 crisis, governments globally are [looking to data-driven technologies](https://www.bloomberg.com/news/articles/2020-04-30/the-world-embraces-contact-tracing-technology-to-fight-covid-19?utm_campaign=The%20Interface&utm_medium=email&utm_source=Revue%20newsletter) to keep cases low, or to facilitate the transition from lockdown to a semblance of normalcy. The technologies being claimed to protect, prevent and track include: \[symptom tracking apps\](https://dai0-my.sharepoint.com/personal/chloe_messenger_dai_com/Documents/DAI Digital/8. Blog/2020/corona.asan.gov.af) to help us understand the disease, digital contact tracing apps to alert us to our interaction with the virus, quarantine enforcement apps that report on people (such as those in Hong Kong, Poland and Kazakhstan; proposed in Russia and Egypt), and[ immunity certification](https://www.ukauthority.com/articles/open-university-develops-digital-certificate-for-covid-19-immunity/) to allow those who have had COVID-19 to be identified.

In more developed nations such as the UK and USA, conversations around data privacy are rife, such as [negotiations](https://www.bbc.co.uk/news/technology-52441428) between the UK National Health Service (NHS) and Google and Apple around the efficacy of their proposed contact-tracing app in light of their stringent adherence to privacy.
In the face of threats, many of us might say there are reasonable expectations that our government will use technology to track and pre-empt the risks we face. In the same way we might expect protection from terrorist attacks, we may accept such measures can help mitigate the effects of public health threats, like the COVID-19 pandemic.

But the vital question is: to what extent are such measures an overreach?

<!--more-->

![photo-1585411241969-9ac0c565451b.webp](/uploads/photo-1585411241969-9ac0c565451b.webp)`Photo Courtesy: Brian McGowan from Unsplash.`

A recent report by the [Brookings](https://www.brookings.edu/research/freedom-and-privacy-in-the-time-of-coronavirus/) Institute argues that the social benefits of an anonymised (mandatory) contact-tracing system are worth the temporary privacy costs. [Privacy International](https://privacyinternational.org/long-read/3675/theres-app-coronavirus-apps) recognise the potential of such apps, but caveat with the need for trust, built through vigilant monitoring, scrutiny and testing. We have already seen how these apps do and do not work. In [South Korea](https://www.theguardian.com/world/2020/mar/06/more-scary-than-coronavirus-south-koreas-health-alerts-expose-private-lives), the app have been lauded with successfully keeping on top of cases, yet messages which trace the movement of people recently diagnosed with COVID-19 have been exposing the private lives of individuals, leading to speculation of extramarital affairs or private medical appointments.

Prior to the COVID-19 outbreak, the [Carnegie Endowment for International Peace](https://carnegieendowment.org/2019/09/17/global-expansion-of-ai-surveillance-pub-79847) published a report on the expansion of surveillance technologies. They found that “the most important factor determining whether governments will deploy this technology for repressive purposes is the quality of their governance.”

In many of countries in which we work, the wider political, economic and security factors may not allow for people to engage in robust debates about privacy and security. Therefore, there is a greater risk that the roll-out of contact tracing or disease tracking technologies will set a dangerous precedent that in the long term will infringe on people’s rights. As the world continues to look for the best approaches to reopen economies while keeping their populations safe, here are some factors we think are important to consider based on lessons we’ve learned from implementing digital development projects for over a decade.

## Trust

Trust in government is not a luxury afforded to populations in many countries, due to rife corruption, institutionalized discrimination, lack of access to reliable resources, or other factors. Even in countries where the government may be widely trusted, emergency measures may undermine this trust. In India, those [returning from abroad](https://www.news18.com/news/india/privacy-not-a-concern-checking-virus-spread-is-ktaka-govt-publishes-details-of-foreign-returnees-2550835.html) to Karnataka had their personal medical data published by the government. It has been [well noted](https://onezero.medium.com/immunity-passports-could-create-a-new-category-of-privilege-2f70ce1b905) that flagging someone as having been infected with COVID-19 or not could have longer term implications (for instance for someone who does not have ‘immunity’ may have less freedoms), and information as personal as medical data in general could have longer term implications for as persons social and economic life.

For marginalised communities or those living in repressive regimes, the potential for the government – or other groups - having any of their personal data, or knowing their location or movements, could put them and their families at increased risk of harm.

## Less robust data protection legislation

Trust also extends to the opportunities for redress or the backing to do so. [UNCTAD analysis](https://unctad.org/en/Pages/DTL/STI_and_ICTs/ICT4D-Legislation/eCom-Data-Protection-Laws.aspx) found that 19 per cent of countries have no data protection and privacy legislation, and only 43 percent of African countries have any data privacy laws. According to Privacy International, in those African countries that do have data privacy laws, [critics and advocates](https://privacyinternational.org/long-read/3109/africa-sim-card-registration-only-increases-monitoring-and-exclusion) have raised concerns about the lack of sufficient protections and safeguards. Vulnerable communities, or those living in repressive states, in particular may feel that they cannot seek redress for the violation of their privacy rights. For instance, there is no law in China to regulate the use of surveillance cameras, which in in some cities are being installed [without warning](https://edition.cnn.com/2020/04/27/asia/cctv-cameras-china-hnk-intl/index.html?utm_campaign=The%20Interface&utm_medium=email&utm_source=Revue%20newsletter) outside the homes of people being quarantined. Citizens therefore cannot seek redress for the increased monitoring they are facing.

## Digital literacy and Cyber Hygiene

In many of the countries in which we work, digital literacy is lower and smartphones, where used, are relatively new to the market. Users entering digital platforms for the first time are particularly vulnerable to data privacy concerns, such as accepting user agreements which compromise their data, or downloading false apps which are covers for ransomware, such as [COVIDLock](https://www.domaintools.com/resources/blog/covidlock-mobile-coronavirus-tracking-app-coughs-up-ransomware). Already, the digital marketplace is full of [false COVID-19](https://www.zdnet.com/article/thousands-of-covid-19-scam-and-malware-sites-are-being-created-on-a-daily-basis/) websites or applications. A time of such crisis, demands that we increase our investment in [digital literacy](https://dai-global-digital.com/the-missing-digital-principle-educate-the-user.html). This includes not only helping people learn how to use web and mobile based apps, but also basic practices that help protect their accounts and information. This could include, teaching people how to create strong passwords, explaining to people why its important to change those passwords frequently, and explaining why its important to update software and avoid purchasing pirated versions of programs.

## Cultural differences

Linked to the above point of differing contexts and data protection legislation, we must also consider the different attitudes towards data privacy and government role. There are already numerous analyses of different cultural attitudes to the coronavirus pandemic, such as the extent to which some nations are more individualistic or obedient and how this affects adherence to quarantine measures.

In China, tracing app *Health Code* isn’t too much of a departure from the social credit system, whereby data about your life such as timely payment of bills can grant you access to various services. This is not to say that the population are more willing to adhere, but that such oversight of everyday movements is already commonplace. Attitudes towards privacy are both an issue of digital skills and culture: [Web Foundation research](https://webfoundation.org/2019/10/personal-data-protection-in-indonesia-the-long-road-to-effective-implementation/) in Indonesia found that citizens generally do not see personal data and privacy as part of their rights as citizens.

*We don’t have time to solve global issues around data protection policies (or lack thereof) in the digital world. But equally, this doesn’t mean we should wait: We understand the value of contact tracing and the benefits of using technology to do so, nevertheless doing so may set dangerous precedent to violate people’s privacy. Therefore, its important always to design with the principles of do no harm*