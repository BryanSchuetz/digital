---
title: Five Resources on Human Rights and Tech
date: 2019-12-10 12:12:00 -05:00
tags:
- Privacy
- Governance
- Digital Inclusion
Author: Chloe Messenger
social-image: "/uploads/Eleanor_roosevelt_human_rights_english_-_Resize_548w.jpg-f6b73d.png"
thumbnail: "/uploads/Eleanor_roosevelt_human_rights_english_-_Resize_548w.jpg-f6b73d.png"
---

This week marked the 71st anniversary of the [Universal Declaration of Human Rights.](https://www.un.org/en/universal-declaration-human-rights/)(UNDHR)—a founding document which set out, for the first time, fundamental human rights to be universally protected. Working in international development, most of us are committed to the 30 rights laid out in the UNDHR. As the digital revolution evolves, countries have adopted a myriad of legal frameworks to protect citizens in the digital space. These laws include those focused on privacy and data protection. However, often, these policies are not aligned with the most recent technological advancements. 

In the humanitarian and development sectors, we are digitising faster than the [legal and ethical frameworks](https://reliefweb.int/report/world/future-financial-assistance-outlook-2030-enaresfr) governing this digitisation. Some fear that the technology sector remains virtually a [human rights-free zone](https://www.ohchr.org/EN/NewsEvents/Pages/DisplayNews.aspx?NewsID=25156).

<!--more-->

![Eleanor_roosevelt_human_rights_english_-_Resize_548w.jpg.png](/uploads/Eleanor_roosevelt_human_rights_english_-_Resize_548w.jpg.png)`Eleanor Roosevelt and the UNDHR in November 1949. Photo: Wikimedia Commons.`

To fulfill the mandate of the UNDHR today, we need to fully understand what this looks like in a digital world and mandate responsibilities, accountability, beyond non-binding ethical frameworks and guidance notes. Indeed, in the recently released “[contract for the web](https://contractfortheweb.org/principles/principle-3-respect-and-protect-peoples-fundamental-online-privacy-and-data-rights/)”, [Tim Berners-Lee](https://webfoundation.org/about/sir-tim-berners-lee/) outlines three principles for the internet, one which aims to“respect and protect people's fundamental online privacy and data rights.”  He asserts that these protections must be underpinned by rule of law, and applicable to all people and data.

The need for these types of laws are clear, as examples of  how technology is being used to violate human rights grows. We're all familiar with examples of how [social media](https://www.freedomonthenet.org/report/freedom-on-the-net/2019/the-crisis-of-social-media) platforms are used for surveillance or electoral manipulation, but the bigger ethical question this poses is whether the architecture of these platforms is itself the problem that eases the possibility of human rights violations. For instance, each of these social media platforms is governed by algorithms that manipulate our access to information and therefore may disadvantage one person over another in a job search or provide only one side of the story during civic strife. (If you're interested in reading more about the impact of algorithmic bias, I highly recommend reading *Weapons of Math Destruction* by Cathy O'Niel). Since social media in many cases has become a public space, does it's own architecture as a curator of information based on algorithms abuse our human rights?

What about biometrics? The [case](https://www.aljazeera.com/indepth/opinion/kenya-huduma-data-commodification-government-tyranny-190806134307370.html) of Huduma Namba in Kenya is an interesting one: a national ID registration system which made biometric registration compulsory for access to basic goods and services. Citizens therefore had to decide between giving up their biometric data and losing access to government services. This was seen as a violation of the right to privacy, right to equality, and the right to non-discrimination, as well as the right to public participation. Eventually, Huduma Namba was mandated by the court to make registration voluntary and benefits not conditional on registration.

The recognition that technology platforms can be inherently abusive, or can be used to disadvantage those more vulnerable, is increasingly recognised. Accordingly there are numerous calls on developers to ensure that human rights are intrinsic to design, using processes such as human-centered design to properly assess risks, needs and wishes of the target audience.

We could share an endless list of recommendations covering the 30 rights, from privacy to freedom of expression. But here are five articles and reports that we have read recently, that have sparked our thinking in this area:

## 1. Report of the Special rapporteur on extreme poverty and human rights on the digital welfare state

The[ report ](https://undocs.org/A/74/493)presents the almost dystopian future we are stumbling into. He raises concerns that, despite numerous analysis of human rights implications of technologies such as AI and biometrics, no protections are currently grounded in law.

## 2.Omidyar Network Ethical Operating System

The Ethical OS is a [guide](https://www.omidyar.com/investees/ethical-os) to anticipating the future impact of today’s technology. The aim of the guide is to help makers of technology, product managers and others see problems before they arise. It aims to help with good design, providing a comprehensive list of potential risks that need to be thought about upfront.

## 3.Engineering and lawyering privacy by design: understanding online privacy both as a technical and an international human rights issue.

Adamantia Rachovitsa [outlines](https://academic.oup.com/ijlit/article/24/4/374/2566975) why privacy – as a fundamental human right – is not just a human rights issue, but should be a design feature of technological solutions.

![thought-catalog-tRL_Rkh6D8o-unsplash.jpg](/uploads/thought-catalog-tRL_Rkh6D8o-unsplash.jpg)`Photo by Thought Catalog on Unsplash`

## 4. Human rights by Design: The Responsibilities of Social Media Platforms to Address Gender‐Based Violence Online.

This [article](https://onlinelibrary.wiley.com/doi/full/10.1002/poi3.185) argues that online gender-based violence cannot be addressed by government legal systems, but need to be address by technology companies in their very design.

## 5. Algorithms and Human Rights by the Council of Europe

The[ report ](https://rm.coe.int/algorithms-and-human-rights-en-rev/16807956b5)does what I just didn’t have space for in this article: it goes through each of the human rights from “fair trial and due process” to “freedom of expression” and outlines how algorithms can impact on human rights. It’s a long read, but worth it for those wanting to really dig into the topic.

We hope to continue the conversation on human rights in the ICT4D space. Tweet us at @DAIGlobal and @ChloeMessenger any reading you recommend!