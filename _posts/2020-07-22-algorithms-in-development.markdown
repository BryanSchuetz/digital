---
title: Algorithms in Development
date: 2020-07-22 14:13:00 -04:00
Author: Gratiana Fu
---

Algorithms. In the age of Big Tech and social media, the term algorithm gets thrown around a lot to describe the black box that determines what people see on social media or the suggestions that they receive on Netflix. But what exactly is an algorithm?

<!--more-->

Algorithms are simple. By definition, an algorithm is a set of rules used to achieve a specific objective. These rules can be implemented in different ways – not just by computers. For example, for me to fully wake up every day, there are many things that I must do:

1. Wake up

2. Take a shower

3. Drink some coffee

These three steps I take and the order I do them in are an algorithm.

![algorithms.PNG](/uploads/algorithms.PNG)

Let's move onto algorithmic bias. Algorithmic bias refers to the errors that appear in algorithms that lead to unfair outcomes. What does that look like in practice? Let’s go back to coffee and waking up. If we ask three other people what steps they take to get ready in the morning, their answers are a little bit different. The first person exercises, showers, and drinks coffee. The second drinks coffee, brushes their teeth, and eats breakfast while the third brushes their teeth before drinking coffee, and eats breakfast.

![icons.PNG](/uploads/icons.PNG)

If we were to create a set of rules to explain or predict the steps that every person in the entire world take to get ready in the morning based on these three people, it would be a very bad algorithm. It would fail to recognize people who don’t drink coffee.

This is an vast oversimplification of algorithmic bias but it shows how each individual perspective and life experience influences the rules and methods that we choose to complete the same objective. The rules matter a lot more when the stakes are higher – algorithmic bias shows up everywhere, from [search engines](https://time.com/5318918/search-results-engine-google-bias-trusted-sources/) to [hiring practices](https://resources.workable.com/stories-and-insights/unconscious-bias-in-recruitment) to [healthcare delivery](https://news.uchicago.edu/story/health-care-prediction-algorithm-biased-against-black-patients-study-finds).

There are a number of mobile applications out there that help to detect skin cancer – you take a picture of a mole or discoloration on your skin and the algorithm tells you whether it could be cancerous or not. It’s a useful tool that provides a way to pre-screen people before going to see a specialist. But a study found that these applications are more accurate at detecting skin cancer on people with white or pale skin versus black and brown skin. A story came out last month about Malone Mukwende, a second-year medical student at St. George’s in London who created a booklet on clinical care guidelines for people with Black and brown skin – he wanted to bring awareness of how symptoms of certain diseases present differently on darker skin, something that had not been addressed in his formal medical education.

![ou_200710_bame_handbook_kawasaki_disease_malone_mukwende_575x600.jpg](/uploads/ou_200710_bame_handbook_kawasaki_disease_malone_mukwende_575x600.jpg)

There will be more opportunities to use advanced algorithms for diagnostics, as well as in other health and non-related fields. However, we have to learn from the mistakes that have been made in to ensure that the tools we use are not favoring or excluding any individual or group. Applications of AI and machine learning techniques in many of the countries that our team work in are still relatively nascent.

Additional resources:

1. [Algorithms of Oppression](https://nyupress.org/9781479837243/algorithms-of-oppression/) by Dr. Safiya Noble

2. [Automating Inequality](https://us.macmillan.com/books/9781250074317) by Virginia Eubanks

3. [Data Feminism](https://data-feminism.mitpress.mit.edu/) by Catherine D’Ignazio and Lauren F. Klein