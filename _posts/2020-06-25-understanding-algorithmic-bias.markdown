---
title: How Technology Can Reflect Human Bias—And Resources to Understand It
date: 2020-06-25 08:43:00 -04:00
tags:
- Digital Inclusion
Author: Center for Digital Acceleration Staff
social-image: "/uploads/AI%202%20copy%20(002).jpg"
thumbnail: "/uploads/AI%202%20copy%20(002).jpg"
---

With each technological advancement, more decisions in our daily lives are made by algorithms. They increasingly determine what advertisements we see, whether we’re considered for a job, or which books and movies are recommended to us—and how and where law enforcement is deployed in our communities. The ongoing protests to draw attention to, and eradicate, systemic racism in the United States, and in other parts of the world, have made clear something we already knew—humans are biased. Because we are biased, the technology we create is biased, too.

Over the next several months DAI's Center for Digital Acceleration will explore this topic by trying to answer the following questions (and more) in a new series: How pervasive is algorithmic bias, and which platforms are the worst offenders? (b) How does algorithmic bias work, and how we can tackle it at a technological level? (c) What other responses—policy, digital literacy, and so on—exist to tackle this phenomenon? (d) What are the effects of algorithmic bias on the broader digital development sector?

<!--more-->

In the meantime, and as we learn more as a team, here is a list of resources we’ve found useful.

![AI 2 copy (002).jpg](/uploads/AI%202%20copy%20(002).jpg)

## Resources

**Articles**

* “[Dissecting racial bias in an algorithm used to manage the health of populations](https://science.sciencemag.org/content/366/6464/447),” *Science Magazine.* By Ziad Obermeyer, Brian Powers, Christine Vogeli, and Sendhil Mullainathan.

* “[Facial recognition fails on race, government study says](https://www.bbc.com/news/technology-50865437),” *BBC.*

* “[Biased policing is made worse by errors in pre-crime algorithms](https://www.newscientist.com/article/mg23631464-300-biased-policing-is-made-worse-by-errors-in-pre-crime-algorithms/#ixzz6PchoHZu1),” *New Scientist.* By Matt Reynolds.

* “[Reclaiming the stories that algorithms tell](https://www.oreilly.com/radar/reclaiming-the-stories-that-algorithms-tell/),” O’Reilly.com. By David G. Grossman.

* “[Algorithmic bias detection and mitigation: Best practices and policies to reduce consumer harms](https://www.brookings.edu/research/algorithmic-bias-detection-and-mitigation-best-practices-and-policies-to-reduce-consumer-harms/),” Brookings Institute. By Nicol Turner Lee, Paul Resnick, and Genie Barton.

* “[I know some algorithms are biased—because I created one](https://blogs.scientificamerican.com/voices/i-know-some-algorithms-are-biased-because-i-created-one/),” *Scientific American.* By Nicholas T. Young.

* “[Discrimination through optimization: How Facebook's ad delivery can lead to skewed outcomes](https://arxiv.org/pdf/1904.02095.pdf),” Cornell University,. By Muhammad Ali, Piotr Sapiezynski, Miranda Bogen, Aleksandra Korolova, Alan Mislove, and Aaron Rieke.

* “[Racial disparities in automated speech recognition](https://www.pnas.org/content/117/14/7684),” PNAS. By Allison Koenecke, Andrew Nam, Emily Lake, Joe Nudell, Minnie Quartey, Zion Mengesha, Connor Toups, John R. Rickford, Dan Jurafsky, and Sharad Goel.

* “[Why racial bias is still inherent in biometric tech](https://www.raconteur.net/technology/biometrics-ethics-bias)”, *Raconteur.* By Peter Yeung.

**Books**

* Charlton Mcllwain, *Black Software: The Internet & Racial Justice, from the AfroNet to Black Lives Matter*

* Safiya Umoja Noble, *Algorithms of Oppression: How Search Engines Reinforce Racism*

* Cathy O’Neil, *Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy*

* Hannah Fry, *Hello World*: *How to be Human in the Age of the Machine*

* Caroline Criado Perez, *Invisible Women: Exposing Data Bias in a World Designed for Men*

**Other Resources**

* The film “[Coded Bias](https://www.hrwfilmfestivalstream.org/film/coded-bias/)” follows the work of women who seek to expose racial and gender bias in technology.

* Reflections from [The Engine Room](https://www.theengineroom.org/tech-bias-people-bias/)

* *Future Tense* frequently publishes articles about algorithmic bias—see [here](https://slate.com/technology/2020/02/algorithmic-bias-people-with-disabilities.html) and [here](https://slate.com/technology/2020/03/ice-lawsuit-hijacked-algorithm.html).

* Data & Society’s [AI On The Ground Initiative](https://datasociety.net/research/ai-on-the-ground/)

* *ProPublica’s* [Machine Bias](https://www.propublica.org/series/machine-bias) research

* University of Pennsylvania's [Toolkit for Centering Racial Equity Throughout Data Integration](https://www.aisp.upenn.edu/equity-toolkit/)

* [Research](https://www.ajlunited.org/library/research) from the Algorithmic Justice League

* [Insights](https://cdt.org/insights/?keyword=Algorithmic\+bias&area-of-focus%5B%5D=ai-machine-learning#results) from the Center for Democracy and Technology

* Report by [AI Now Institute](https://ainowinstitute.org/reports.html) housed at NYU