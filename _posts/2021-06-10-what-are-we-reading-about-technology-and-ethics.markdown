---
title: What Are We Reading about Technology and Ethics?
date: 2021-06-10 08:00:00 -04:00
tags:
- AI
- Machine Learning
Author: Gratiana Fu
social-image: "/uploads/Gratiana%202.PNG"
thumbnail: "/uploads/Gratiana%202.PNG"
---

Tech ethics have continued to claim the public spotlight as more accounts of bias and harm due to technology and artificial intelligence (AI) have appeared in the media. Stories from racial bias in [health care algorithms](https://www.nature.com/articles/d41586-019-03228-6) to gender bias in [hiring algorithms](https://mashable.com/article/amazon-sexist-recruiting-algorithm-gender-bias-ai/) have uncovered the lack of neutrality in technology that has previously been assumed to be completely objective and neutral. 

<!--more-->

In response to these growing concerns, DAI’s Center for Digital Acceleration (CDA) has organized our own monthly technology book and media club to learn more from prominent scholars in the field. So far we have covered [Meredith Broussard](https://merbroussard.github.io/)’s *[Artificial Unintelligence](https://mitpress.mit.edu/books/artificial-unintelligence)*, watched the documentary *[Coded Bias](https://www.codedbias.com)*, and are gearing up for our next meeting on [Safiya Noble](https://safiyaunoble.com/)’s *[Algorithms of Oppression](http://algorithmsofoppression.com/)*.

In addition to these, we’ve also been keeping track of our favorite websites and organizations on this topic of ethical technology, particularly those that operate with an international lens. In another installment of our “What Are We Reading” series, here is a snapshot of what CDA is reading about ethics, technology, and AI:

[AI Now Institute](https://ainowinstitute.org)—At New York University, the institute is a research center founded by [Meredith Whittaker](https://ainowinstitute.org/people/meredith-whittaker.html) and [Kate Crawford](https://katecrawford.net) that studies the social implications of artificial intelligence with a focus on rights and liberties, labor and automation, bias and inclusion, and safety and critical infrastructure. The organization has published findings on [regulating biometrics](https://ainowinstitute.org/regulatingbiometrics.pdf), [disability in AI](https://ainowinstitute.org/disabilitybiasai-2019.html), and [gender, race, and power in AI](https://ainowinstitute.org/discriminatingsystems.html). Though based in New York, the institute has its pulse on the latest data and AI policies around the world and creates incredibly helpful resources and reports for policymakers and governments (like this [Algorithmic Accountability Policy Toolkit](https://ainowinstitute.org/research.html)) to better understand and use AI.

[Algorithmic Justice League](http://www.ajl.org)—Founded by poet of code and AI researcher Joy Buolamwini, the Algorithmic Justice League uses art and research to raise awareness of the social implications and harms of AI. It offers workshops such as [#DRAGVSAI](https://www.ajl.org/drag-vs-ai) to teach people the basics of AI, bias, and harms and provide actionable resources to identifying and understanding the implications of AI. The documentary *[Coded Bias](https://www.codedbias.com/)*, available on Netflix and PBS (in the United States), is also a great watch that follows Buolamwini and the impact of facial recognition technologies across the globe.

[All Tech is Human](https://alltechishuman.org/)—This group connects technologists from around the world to “build the responsible tech pipeline.” In addition to its [resources](https://alltechishuman.org/blog) on how to be a responsible technology worker, it has an active Slack community of almost 1,500 technologists from all corners of the world.

[Data for Black Lives (DB4L)](https://d4bl.org/)—A movement of scientists and activists dedicated to using data to change the lives of Black people, D4BL has hubs of people across the country that use data to address issues in their respective communities. Its latest [report](https://datacapitalism.d4bl.org/documents/Demos_Data_Capitalism_Final.pdf) analyzes data capitalism, “an economic model built on the extraction and commodification of data and the use of big data and algorithms as tools to concentrate and consolidate power in ways that dramatically increase inequality along lines of race, class, gender, and disability.” The report’s accompanying [website](https://datacapitalism.d4bl.org/) provides a beautiful, clear summary of data capitalism to read, if you are short on time.

[Data & Society](https://datasociety.net)—A nonprofit research organization that studies the “social implications of data and automation, Data & Society produces original research to ground informed, evidence-based public debate about emerging technology.” Its work ranges from [technology for workplace surveillance](https://datasociety.net/wp-content/uploads/2021/05/The_Constant_Boss.pdf) to [challenges of building healthy technology for young people](https://datasociety.net/wp-content/uploads/2021/05/The-Unseen-Teen-.pdf). Catch more from Data & Society on [“Becoming Data,”](https://datasociety.net/library/trailer-becoming-data/) the third season of the Public Books 101 podcast, as its members discuss the role of data in shaping humanity. Episode 3, featuring researchers Deb Raji and Arthur Gwagwa, might be of particular interest to readers as it discusses the different ways data and AI operate across the United States and Africa.

![Gratiana 2.PNG](/uploads/Gratiana%202.PNG)

[Montreal AI Ethics Institute](montrealethics.ai)—The institute is an international nonprofit “democratizing AI ethics literacy.” Its weekly newsletter, [the AI Ethics Brief](https://brief.montrealethics.ai), provides a fantastic summary of the latest research and news in ethics and AI.

![Gratiana 1.PNG](/uploads/Gratiana%201.PNG)

These are just a handful of the resources we have been following. As the intersection of ethics and technology continues to grow, especially in the development space, we’ll be keeping our eyes out for more resources and knowledge to share.